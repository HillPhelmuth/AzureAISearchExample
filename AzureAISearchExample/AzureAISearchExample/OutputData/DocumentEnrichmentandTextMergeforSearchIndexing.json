{
  "Id": "1062",
  "Title": "\u0022Document Enrichment and Text Merge for Search Indexing\u0022",
  "Text": "C:\\Users\\adamh\\Downloads\\azure-search.pdfImages in the queue are normalized and passed into enriched documents as a\u0022document/normalized_images\u0022 node.3. Image enrichments execute, using \u0022/document/normalized_images\u0022 as input.4. Image outputs are passed into enriched documents, with each output as aseparate node. Outputs vary by skill (text and layoutText for OCR, tags andcaptions for Image Analysis).5.\r\nOptional but recommended if you want search documents to include both textand image-origin text together, Text Merge runs, combining the textrepresentation of those images with the raw text extracted from the file. Textchunks are consolidated into a single large string, where the text is inserted first inthe string and then the OCR text output or image tags and captions.\r\nThe output of Text Merge is now the definitive text to analyze for any downstreamskills that perform text processing. For example, if your skillset includes both OCRand Entity Recognition, the input to Entity Recognition should be\u0022document/merged_text\u0022 (the targetName of the Text Merge skill output).6.\r\nAfter all skills have executed, the enriched document is complete. In the last step,indexers refer to output field mappings to send enriched content to individualfields in the search index.The following example skillset creates a \u0022merged_text\u0022 field containing the original textof your document with embedded OCRed text in place of embedded images. It alsoincludes an Entity Recognition skill that uses \u0022merged_text\u0022 as input.JSONRequest body syntax{   \u0022description\u0022: \u0022Extract text from images and merge with content text to produce merged_text\u0022,   \u0022skills\u0022:   [     {         \u0022description\u0022: \u0022Extract text (plain and structured) from image. \u0022,         \u0022@odata.type\u0022: \u0022#Microsoft.Skills.Vision.OcrSkill\u0022,         \u0022context\u0022: \u0022/document/normalized_images/*\u0022,         \u0022defaultLanguageCode\u0022: \u0022en\u0022,         \u0022detectOrientation\u0022: true,         \u0022inputs\u0022: [           {             \u0022name\u0022: \u0022image\u0022,             \u0022source\u0022: \u0022/document/normalized_images/*\u0022           }         ],         \u0022outputs\u0022: [           {             \u0022name\u0022: \u0022text\u0022           }         ]     },     {       \u0022@odata.\n"
}