{
  "Id": "413",
  "Title": "\u0022Enhancing Relevance in Azure AI Search: Techniques and Best Practices\u0022",
  "Text": "C:\\Users\\adamh\\Downloads\\azure-search.pdfWhen you\u0027re working with complex processes, a large amount of data, and expectationsfor millisecond responses, it\u0027s critical that each step adds value and improves the qualityof the end result. On the information retrieval side, relevance tuning is an activity thatimproves the quality of the results sent to the LLM. Only the most relevant or the mostsimilar matching documents should be included in results.\r\nRelevance applies to keyword (non-vector) search and to hybrid queries (over the non-vector fields). In Azure AI Search, there\u0027s no relevance tuning for similarity search andvector queries. BM25 ranking is the ranking algorithm for full text search.Relevance tuning is supported through features that enhance BM25 ranking. Theseapproaches include:Scoring profiles that boost the search score if matches are found in a specificsearch field or on other criteria.Semantic ranking that re-ranks a BM25 results set, using semantic models fromBing to reorder results for a better semantic fit to the original query.\r\nIn comparison and benchmark testing, hybrid queries with text and vector fields,supplemented with semantic ranking over the BM25-ranked results, produce the mostrelevant results.The following code is copied from the retrievethenread.py file from a demo site. Itproduces content for the LLM from hybrid query search results.\r\nYou can write a simplerquery, but this example is inclusive of vector search and keyword search with semanticreranking and spell check. In the demo, this query is used to get initial content.Rank by relevanceExample code of an Azure AI Search query for RAGscenariosPythonA RAG solution that includes Azure AI Search requires other components and code tocreate a complete solution. Whereas the previous sections covered information retrievalthrough Azure AI Search and which features are used to create and query searchablecontent, this section introduces LLM integration and interaction.Notebooks in the demo repositories are a great starting point because they showpatterns for passing search results to an LLM.\n"
}