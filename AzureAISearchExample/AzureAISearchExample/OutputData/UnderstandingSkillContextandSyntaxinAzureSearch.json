{
  "Id": "1023",
  "Title": "\u0022Understanding Skill Context and Syntax in Azure Search\u0022",
  "Text": "C:\\Users\\adamh\\Downloads\\azure-search.pdfSkillreference documentation describes all of the parameters and properties of a given skill.Although there are differences, most skills share a common set and are similarlypatterned.Each skill has a context property that determines the level at which operations takeplace. If the \u0022context\u0022 property isn\u0027t explicitly set, the default is \u0022/document\u0022, where thecontext is the whole document (the skill is called once per document).\r\nJSONContext is usually set to one of the following examples:              \u0022name\u0022: \u0022brands\u0022          }      ]  }]\uFF17 NoteYou can build complex skillsets with looping and branching using the Conditionalskill to create the expressions. The syntax is based on the JSON Pointer pathnotation, with a few modifications to identify nodes in the enrichment tree.\r\nA \u0022/\u0022traverses a level lower in the tree and \u0022*\u0022 acts as a for-each operator in thecontext. Numerous examples in this article illustrate the the syntax.Set skill context\u0022skills\u0022:[  {    \u0022@odata.type\u0022: \u0022#Microsoft.Skills.Text.V3.EntityRecognitionSkill\u0022,    \u0022context\u0022: \u0022/document\u0022,    \u0022inputs\u0022: [],    \u0022outputs\u0022: []  },  {      \u0022@odata.type\u0022: \u0022#Microsoft.Skills.Vision.\r\nImageAnalysisSkill\u0022,      \u0022context\u0022: \u0022/document/normalized_images/*\u0022,      \u0022visualFeatures\u0022: [],      \u0022inputs\u0022: [],      \u0022outputs\u0022: []  }]Context exampleDescription\u0022context\u0022: \u0022/document\u0022(Default) Inputs and outputs are at the document level.\u0022context\u0022: \u0022/document/pages/*\u0022Some skills like sentiment analysis perform better oversmaller chunks of text. If you\u0027re splitting a large contentfield into pages or sentences, the context should be overeach component part.\u0022context\u0022:\u0022/document/normalized_images/*\u0022For image content, inputs and outputs are one per imagein the parent document.Context also determines where outputs are produced in the enrichment tree. Forexample, the Entity Recognition skill returns a property called \u0022organizations\u0022, capturedas orgs.\n"
}