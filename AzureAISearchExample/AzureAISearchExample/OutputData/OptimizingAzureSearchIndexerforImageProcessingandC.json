{
  "Id": "1058",
  "Title": "\u0022Optimizing Azure Search Indexer for Image Processing and Content Types\u0022",
  "Text": "C:\\Users\\adamh\\Downloads\\azure-search.pdfIndexer execution will emit warnings if imaging inputs are empty.Such warnings are to be expected when nodes are unpopulated in the enricheddocument. Recall that blob indexing lets you include or exclude file types if you want towork with content types in isolation. You can use these setting to reduce noise duringindexer runs.An alternate query for checking results might include the \u0022content\u0022 and\u0022merged_content\u0022 fields.\r\nNotice that those fields will include content for any blob file,even those where there was no image processing performed.Skill outputs include \u0022text\u0022 (OCR), \u0022layoutText\u0022 (OCR), \u0022merged_content\u0022, \u0022captions\u0022(image analysis), \u0022tags\u0022 (image analysis):\u0022text\u0022 stores OCR-generated output. This node should be mapped to field of typeCollection(Edm.\r\nString). There is one \u0022text\u0022 field per search document consistingof comma-delimited strings for documents that contain multiple images. Thefollowing illustration shows OCR output for three documents. First is a documentcontaining a file with no images. Second is a document (image file) containing oneword, \u0022Microsoft\u0022.\r\nThird is a document containing multiple images, some withoutany text (\u0022\u0022,).JSONAbout skill outputs\u0022value\u0022: [     {         \u0022@search.score\u0022: 1,         \u0022metadata_storage_name\u0022: \u0022facts-about-microsoft.html\u0022,         \u0022text\u0022: []     },     {         \u0022@search.score\u0022: 1,         \u0022metadata_storage_name\u0022: \u0022guthrie.jpg\u0022,         \u0022text\u0022: [ \u0022Microsoft\u0022 ]     },     {         \u0022@search. score\u0022: 1,         \u0022metadata_storage_name\u0022: \u0022Cognitive Services and Content Intelligence.pptx\u0022,         \u0022text\u0022: [             \u0022\u0022,             \u0022Microsoft\u0022,             \u0022\u0022,             \u0022\u0022,             \u0022\u0022, \u0022layoutText\u0022 stores OCR-generated information about text location on the page,described in terms of bounding boxes and coordinates of the normalized image.\n"
}