{
  "Id": "167",
  "Title": "\u0022Batch Insertion of Documents into Azure Search Index\u0022",
  "Text": "C:\\Users\\adamh\\Downloads\\azure-search.pdfcsv\u0027;const BATCH_SIZE = 1000;// Create Search service client// used to upload docs into Indexconst client = new SearchClient(  SEARCH_ENDPOINT,  SEARCH_INDEX_NAME,  new AzureKeyCredential(SEARCH_ADMIN_KEY));// Create Search service Index client// used to create new Indexconst clientIndex = new SearchIndexClient(  SEARCH_ENDPOINT,  new AzureKeyCredential(SEARCH_ADMIN_KEY));// Insert docs into Search Index// in batchconst insertData = async (data) =\u003E {  let batch = 0;  let batchArray = [];  for (let i = 0; i \u003C data.\r\nlength; i\u002B\u002B) {    const row = data[i];    // Convert string data to typed data    // Types are defined in schema    batchArray.push({      id: row.book_id,      goodreads_book_id: parseInt(row.goodreads_book_id),      best_book_id: parseInt(row.best_book_id),      work_id: parseInt(row.work_id),      books_count: !row.books_count ? 0 : parseInt(row.books_count),      isbn: row.isbn,      isbn13: row.isbn13,      authors: row.authors.split(\u0027,\u0027).\r\nmap((name) =\u003E name.trim()),      original_publication_year: !row.original_publication_year        ? 0        : parseInt(row.original_publication_year),      original_title: row.original_title,      title: row.title,      language_code: row.language_code,      average_rating: !row.average_rating ? 0 : parseFloat(row.average_rating),      ratings_count: !row. ratings_count ? 0 : parseInt(row.ratings_count),      work_ratings_count: !row.work_ratings_count        ? 0        : parseInt(row.work_ratings_count),      work_text_reviews_count: !row.work_text_reviews_count        ? 0        : parseInt(row.work_text_reviews_count),      ratings_1: !row.ratings_1 ? 0 : parseInt(row.ratings_1),      ratings_2: !row.\n"
}