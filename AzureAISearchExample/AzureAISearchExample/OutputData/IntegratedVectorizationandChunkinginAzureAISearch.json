{
  "Id": "706",
  "Title": "\u0022Integrated Vectorization and Chunking in Azure AI Search\u0022",
  "Text": "C:\\Users\\adamh\\Downloads\\azure-search.pdftrue, \u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u0022filterable\u0022:\u202Ffalse, \u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u0022sortable\u0022:\u202Ffalse, \u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F\u0022facetable\u0022:\u202Ffalse \u202F\u202F\u202F\u202F\u202F\u202F\u202F\u202F} ]Test a vectorizer1.\r\nRun the indexer. When you run the indexer, the following operations occur:Data retrieval from the supported data sourceDocument crackingSkills processing for data chunking and vectorizationIndexing to one or more indexes2. Query the vector field once the indexer is finished. In a query that uses integratedvectorization:Set \u0022kind\u0022 to \u0022text\u0022.Set \u0022text\u0022 to the string to be vectorized.JSONThere are no vectorizer properties to set at query time. The query uses the algorithmand vectorizer provided through the profile assignment in the index.\r\nIntegrated vectorization (preview)\u0022count\u0022: true,\u0022select\u0022: \u0022title\u0022,\u0022vectorQueries\u0022:\u202F[    {       \u0022kind\u0022: \u0022text\u0022,      \u0022text\u0022: \u0022story about horses set in Australia\u0022,      \u0022fields\u0022:\u202F\u0022synopsis\u0022,      \u0022k\u0022: 5   }]See alsoChunking large documents for vectorsearch solutions in Azure AI SearchArticle\u202211/15/2023This article describes several approaches for chunking large documents so that you cangenerate embeddings for vector search. Chunking is only required if source documentsare too large for the maximum input size imposed by models.The models used to generate embedding vectors have maximum limits on the textfragments provided as input.\nFor example, the maximum length of input text for theAzure OpenAI embedding models is 8,191 tokens. Given that each token is around 4characters of text for common OpenAI models, this maximum limit is equivalent toaround 6000 words of text. If you\u0027re using these models to generate embeddings, it\u0027scritical that the input text stays under the limit.\n"
}