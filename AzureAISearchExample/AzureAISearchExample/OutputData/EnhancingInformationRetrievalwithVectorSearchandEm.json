{
  "Id": "397",
  "Title": "\u0022Enhancing Information Retrieval with Vector Search and Embeddings\u0022",
  "Text": "C:\\Users\\adamh\\Downloads\\azure-search.pdfSemantic kernel is a lightweight SDK enabling integration of AI Large LanguageModels (LLMs) with conventional programming languages. It\u0027s useful for chunkinglarge documents in a larger workflow that sends inputs to embedding models.If you\u0027re new to vectors, this section explains some core concepts.Vector search is a method of information retrieval where documents and queries arerepresented as vectors instead of plain text. In vector search, machine learning modelsgenerate the vector representations of source inputs, which can be text, images, audio,or video content. Having a mathematic representation of content provides a commonbasis for search scenarios.\r\nIf everything is a vector, a query can find a match in vectorspace, even if the associated original content is in different media or in a differentlanguage than the query.Vectors can overcome the limitations of traditional keyword-based search by usingmachine learning models to capture the meaning of words and phrases in context,rather than relying solely on lexical analysis and matching of individual query terms. Bycapturing the intent of the query, vector search can return more relevant results thatmatch the user\u0027s needs, even if the exact terms aren\u0027t present in the document.\r\nAdditionally, vector search can be applied to different types of content, such as imagesand videos, not just text. This enables new search experiences such as multi-modalsearch or cross-language search in multi-lingual applications.Vector search conceptsAbout vector searchWhy use vector searchEmbeddings are a specific type of vector representation of content or a query, createdby machine learning models that capture the semantic meaning of text orrepresentations of other content such as images. Natural language machine learningmodels are trained on large amounts of data to identify patterns and relationshipsbetween words. During training, they learn to represent any input as a vector of realnumbers in an intermediary step called the encoder. After training is complete, theselanguage models can be modified so the intermediary vector representation becomesthe model\u0027s output. The resulting embeddings are high-dimensional vectors, wherewords with similar meanings are closer together in the vector space, as explained inUnderstand embeddings (Azure OpenAI).\n"
}