{
  "Id": "764",
  "Title": "\u0022Advanced Text Processing Options in Azure AI Search\u0022",
  "Text": "C:\\Users\\adamh\\Downloads\\azure-search.pdfMatching is greedy(longest pattern matching at a given point wins).Replacement is allowed to be the empty string.Optionsmappings (type: string array) - A list ofmappings of the following format: a=\u003Eb (alloccurrences of the character a are replaced withcharacter b). Required.pattern_replacePatternReplaceCharFilterA char filter that replaces characters in the inputstring.\r\nIt uses a regular expression to identifycharacter sequences to preserve and areplacement pattern to identify characters toreplace. For example, input text = aa bb aa bb,pattern=(aa)\\\\\\s\u002B(bb) replacement=$1#$2,result = aa#bb aa#bb.Optionspattern (type: string) - Required.replacement (type: string) - Required.\r\nChar Filter Types are always prefixed in code with #Microsoft.Azure.Search such thatMappingCharFilter would actually be specified as#Microsoft.Azure.Search.MappingCharFilter. We removed the prefix to reduce the widthof the table, but please remember to include it in your code. Notice that char_filter_typeis only provided for filters that can be customized.\r\nIf there are no options, as is the casewith html_strip, there\u0027s no associated #Microsoft.Azure.Search type.A tokenizer divides continuous text into a sequence of tokens, such as breaking asentence into words, or a word into root forms.Azure AI Search supports tokenizers in the following list. More information about eachone can be found in the Lucene API reference.\r\n11Tokenizerstokenizer_nametokenizer_type Description andOptionsclassicClassicTokenizerGrammar basedtokenizer that issuitable forprocessing mostEuropean-languagedocuments.OptionsmaxTokenLength(type: int) - Themaximum tokenlength. Default: 255,maximum: 300.Tokens longer thanthe maximum lengthare split. edgeNGramEdgeNGramTokenizerTokenizes the inputfrom an edge into n-grams of givensize(s).OptionsminGram (type: int) -Default: 1, maximum:300.maxGram (type: int) -Default: 2, maximum:300. Must be greaterthan minGram.tokenChars (type:string array) -Character classes tokeep in the tokens.Allowed values:letter, digit,whitespace,punctuation, symbol.\n"
}