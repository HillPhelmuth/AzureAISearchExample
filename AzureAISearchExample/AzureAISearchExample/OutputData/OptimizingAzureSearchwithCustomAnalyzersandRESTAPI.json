{
  "Id": "1272",
  "Title": "\u0022Optimizing Azure Search with Custom Analyzers and REST APIs\u0022",
  "Text": "C:\\Users\\adamh\\Downloads\\azure-search.pdfFor example, you might define \u0022featureCode\u0022 and \u0022featureCodeRegex\u0022 tosupport regular full text search on the first, and advanced pattern matching on thesecond. The analyzers assigned to each field determine how the contents of each fieldare tokenized in the index.JSON\uEA80 TipEvaluating analyzers is an iterative process that requires frequent index rebuilds.\r\nYou can make this step easier by using Postman, the REST APIs for Create Index,Delete Index,Load Documents, and Search Documents. For Load Documents, therequest body should contain a small representative data set that you want to test(for example, a field with phone numbers or product codes).\r\nWith these APIs in thesame Postman collection, you can cycle through these steps quickly.1 - Create a dedicated field{   \u0022name\u0022: \u0022featureCode\u0022,   \u0022type\u0022: \u0022Edm.String\u0022,  \u0022retrievable\u0022: true,   \u0022searchable\u0022: true,   \u0022analyzer\u0022: null }, {   \u0022name\u0022: \u0022featureCodeRegex\u0022,   \u0022type\u0022: \u0022Edm.\r\nString\u0022,  \u0022retrievable\u0022: true,   \u0022searchable\u0022: true,   \u0022analyzer\u0022: \u0022my_custom_analyzer\u0022 }, 2 - Set an analyzerWhen choosing an analyzer that produces whole-term tokens, the following analyzersare common choices:AnalyzerBehaviorslanguageanalyzersPreserves hyphens in compound words or strings, vowel mutations, and verbforms. If query patterns include dashes, using a language analyzer might besufficient. keywordContent of the entire field is tokenized as a single term.whitespaceSeparates on white spaces only. Terms that include dashes or other characters aretreated as a single token.customanalyzer(recommended) Creating a custom analyzer lets you specify both the tokenizerand token filter. The previous analyzers must be used as-is.\n"
}