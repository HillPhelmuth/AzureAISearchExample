{
  "Id": "1273",
  "Title": "\u0022Custom Analyzers in Azure Search: Tokenization and Analyzer Selection\u0022",
  "Text": "C:\\Users\\adamh\\Downloads\\azure-search.pdfkeywordContent of the entire field is tokenized as a single term.whitespaceSeparates on white spaces only. Terms that include dashes or other characters aretreated as a single token.customanalyzer(recommended) Creating a custom analyzer lets you specify both the tokenizerand token filter. The previous analyzers must be used as-is.\r\nA custom analyzer letsyou pick which tokenizers and token filters to use.  A recommended combination is the keyword tokenizer with a lower-case tokenfilter. By itself, the built-in keyword analyzer doesn\u0027t lower-case any upper-case text, which can cause queries to fail. A custom analyzer gives you amechanism for adding the lower-case token filter.\r\nIf you\u0027re using a web API test tool like Postman, you can add the Test Analyzer REST callto inspect tokenized output.You must have a populated index to work with. Given an existing index and a fieldcontaining dashes or partial terms, you can try various analyzers over specific terms tosee what tokens are emitted.1.\r\nFirst, check the Standard analyzer to see how terms are tokenized by default.JSON2. Evaluate the response to see how the text is tokenized within the index. Noticehow each term is lower-cased, hyphens removed, and substrings broken up intoindividual tokens. Only those queries that match on these tokens will return thisdocument in the results. A query that includes \u002210-NOR\u0022 will fail.JSON{ \u0022text\u0022: \u0022SVP10-NOR-00\u0022,\u0022analyzer\u0022: \u0022standard\u0022 } 3. Now modify the request to use the whitespace or keyword analyzer:JSON4. This time, the response consists of a single token, upper-cased, with dashespreserved as a part of the string. If you need to search on a pattern or a partialterm such as \u002210-NOR\u0022, the query engine now has the basis for finding a match.\n"
}