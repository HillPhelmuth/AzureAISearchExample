{
  "Id": "407",
  "Title": "\u0022Integrating Azure AI Search with Language Model for User Interaction\u0022",
  "Text": "C:\\Users\\adamh\\Downloads\\azure-search.pdfA high-level summary of the pattern looks like this:Start with a user question or request (prompt).Send it to Azure AI Search to find relevant information.Send the top ranked search results to the LLM.Use the natural language understanding and reasoning capabilities of the LLM togenerate a response to the initial prompt.\r\nAzure AI Search provides inputs to the LLM prompt, but doesn\u0027t train the model. In RAGarchitecture, there\u0027s no extra training. The LLM is pretrained using public data, but itgenerates responses that are augmented by information from the retriever.RAG patterns that include Azure AI Search have the elements indicated in the followingillustration.\r\nCustom RAG pattern for Azure AI SearchApp UX (web app) for the user experienceApp server or orchestrator (integration and coordination layer)Azure AI Search (information retrieval system)Azure OpenAI (LLM for generative AI)The web app provides the user experience, providing the presentation, context, and userinteraction.\r\nQuestions or prompts from a user start here. Inputs pass through theintegration layer, going first to information retrieval to get the search results, but alsogo to the LLM to set the context and intent.The app server or orchestrator is the integration code that coordinates the handoffsbetween information retrieval and the LLM.\r\nOne option is to use LangChain tocoordinate the workflow. LangChain integrates with Azure AI Search, making it easierto include Azure AI Search as a retriever in your workflow.The information retrieval system provides the searchable index, query logic, and thepayload (query response). The search index can contain vectors or non-vector content. Although most samples and demos include vector fields, it\u0027s not a requirement. Thequery is executed using the existing search engine in Azure AI Search, which can handlekeyword (or term) and vector queries. The index is created in advance, based on aschema you define, and loaded with your content that\u0027s sourced from files, databases, orstorage.\n"
}