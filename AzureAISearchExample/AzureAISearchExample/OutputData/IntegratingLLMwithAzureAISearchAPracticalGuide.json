{
  "Id": "414",
  "Title": "\u0022Integrating LLM with Azure AI Search: A Practical Guide\u0022",
  "Text": "C:\\Users\\adamh\\Downloads\\azure-search.pdfWhereas the previous sections covered information retrievalthrough Azure AI Search and which features are used to create and query searchablecontent, this section introduces LLM integration and interaction.Notebooks in the demo repositories are a great starting point because they showpatterns for passing search results to an LLM.\r\nMost of the code in a RAG solutionconsists of calls to the LLM so you need to develop an understanding of how those APIswork, which is outside the scope of this article.The following cell block in the chat-read-retrieve-read.ipynb notebook shows searchcalls in the context of a chat session:# Use semantic ranker if requested and if retrieval mode is text or hybrid (vectors \u002B text)if overrides.\r\nget(\u0022semantic_ranker\u0022) and has_text:    r = await self.search_client.search(query_text,                                  filter=filter,                                  query_type=QueryType.SEMANTIC,                                  query_language=\u0022en-us\u0022,                                  query_speller=\u0022lexicon\u0022,                                  semantic_configuration_name=\u0022default\u0022,                                  top=top,                                  query_caption=\u0022extractive|highlight-false\u0022 if use_semantic_captions else None,                                  vector=query_vector,                                  top_k=50 if query_vector else None,                                  vector_fields=\u0022embedding\u0022 if query_vector else None)else:    r = await self. search_client.search(query_text,                                  filter=filter,                                  top=top,                                  vector=query_vector,                                  top_k=50 if query_vector else None,                                  vector_fields=\u0022embedding\u0022 if query_vector else None)if use_semantic_captions:    results = [doc[self.sourcepage_field] \u002B \u0022: \u0022 \u002B nonewlines(\u0022 . \u0022.join([c.text for c in doc[\u0027@search.captions\u0027]])) async for doc in r]else:    results = [doc[self.sourcepage_field] \u002B \u0022: \u0022 \u002B nonewlines(doc[self.content_field]) async for doc in r]content = \u0022\\n\u0022.\n"
}